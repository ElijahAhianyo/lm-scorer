{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lm-scorer",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnoX4z8Qvbo0",
        "colab_type": "text"
      },
      "source": [
        "# Setup Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iq4WxoDiV1t3",
        "colab": {}
      },
      "source": [
        "# Install python.\n",
        "!env DEBIAN_FRONTEND=noninteractive apt-get install -y -qq python3 python3-dev python3-venv python3-pip > /dev/null\n",
        "# Upgrade pip\n",
        "!python -m pip install -qq --upgrade pip\n",
        "# Disable TF info logs\n",
        "%env TF_CPP_MIN_LOG_LEVEL=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dhg7FaKiLdN",
        "colab_type": "code",
        "outputId": "1d3b17c5-1d99-48a3-9e9f-09cd6dbdc203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!python --version\n",
        "!pip --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n",
            "pip 20.0.2 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIE59LALvjmE",
        "colab_type": "text"
      },
      "source": [
        "# Install lm-scorer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPIZ7D2avgmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "970445cb-af5d-4ef6-ef88-aef5dffd79a1"
      },
      "source": [
        "!pip install lm-scorer\n",
        "!pip show lm-scorer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: lm-scorer\n",
            "Version: 0.2.3\n",
            "Summary: Language Model based sentences scoring library\n",
            "Home-page: https://github.com/simonepri/lm-scorer#readme\n",
            "Author: Simone Primarosa\n",
            "Author-email: simonepri@outlook.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: torch, pip, transformers\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAWCMVnC9Nqv",
        "colab_type": "text"
      },
      "source": [
        "# Run the CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGEGKmPoTd5U",
        "colab_type": "code",
        "outputId": "08202005-71a2-4565-bce3-533e4adb750e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "!lm-scorer -h"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: lm-scorer [-h] [--model-name MODEL_NAME] [--tokens] [--log-prob]\n",
            "                 [--reduce REDUCE] [--cuda CUDA] [--debug]\n",
            "                 sentences-file-path\n",
            "\n",
            "Get sentences probability using a language model.\n",
            "\n",
            "positional arguments:\n",
            "  sentences-file-path   A file containing sentences to score, one per line. If\n",
            "                        - is given as filename it reads from stdin instead.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model-name MODEL_NAME, -m MODEL_NAME\n",
            "                        The pretrained language model to use. Can be one of:\n",
            "                        gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2.\n",
            "  --tokens, -t          If provided it provides the probability of each token\n",
            "                        of each sentence.\n",
            "  --log-prob, -lp       If provided log probabilities are returned instead.\n",
            "  --reduce REDUCE, -r REDUCE\n",
            "                        Reduce strategy applied on token probabilities to get\n",
            "                        the sentence score. Available strategies are: prod,\n",
            "                        mean, gmean, hmean.\n",
            "  --cuda CUDA           If provided it runs the model on the given cuda\n",
            "                        device.\n",
            "  --debug               If provided it provides additional logging in case of\n",
            "                        errors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHNGxhLbTNVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile sentences.txt\n",
        "I am going to run a marathon.\n",
        "I am go to run a marathon."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing sentences.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qwePYUHz87Z",
        "colab_type": "code",
        "outputId": "c382da63-d007-4eca-8da2-13cb84cc4478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!lm-scorer -lp --cuda 0 sentences.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am going to run a marathon.\t-32.551\n",
            "I am go to run a marathon.\t-42.834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfcZmxLzUSvb",
        "colab_type": "code",
        "outputId": "532ee25e-9a16-43bb-93a4-656cf37e2c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!lm-scorer -lp -t --cuda 0 sentences.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am going to run a marathon.\t-32.551\n",
            "I\t-3.9997\n",
            "Ġam\t-3.0501\n",
            "Ġgoing\t-3.4329\n",
            "Ġto\t-0.075378\n",
            "Ġrun\t-5.6097\n",
            "Ġa\t-1.6184\n",
            "Ġmarathon\t-5.9767\n",
            ".\t-2.3148\n",
            "<|endoftext|>\t-6.4729\n",
            "\n",
            "I am go to run a marathon.\t-42.834\n",
            "I\t-3.9997\n",
            "Ġam\t-3.0501\n",
            "Ġgo\t-10.555\n",
            "Ġto\t-4.5773\n",
            "Ġrun\t-6.7563\n",
            "Ġa\t-1.8721\n",
            "Ġmarathon\t-3.8127\n",
            ".\t-1.9487\n",
            "<|endoftext|>\t-6.2627\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
